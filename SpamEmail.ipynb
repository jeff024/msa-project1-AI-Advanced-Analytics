{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Spam filter\n",
    "\n",
    "### Abstract\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "### DataSet\n",
    "This project used the Dataset downloaded from \"https://archive.ics.uci.edu/ml/datasets/Spambase\" which refers to sample Project 3 in MSA project AI & Advanced Analysis (A ML model to identify emails are spam or not - Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading dataset files\n",
    "dataset = pd.read_csv(\"dataset/spambase.data\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9  ...    48     49  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
       "\n",
       "    50     51     52     53     54   55    56  57  \n",
       "0  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "30    0\n",
       "31    0\n",
       "32    0\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "36    0\n",
       "37    0\n",
       "38    0\n",
       "39    0\n",
       "40    0\n",
       "41    0\n",
       "42    0\n",
       "43    0\n",
       "44    0\n",
       "45    0\n",
       "46    0\n",
       "47    0\n",
       "48    0\n",
       "49    0\n",
       "50    0\n",
       "51    0\n",
       "52    0\n",
       "53    0\n",
       "54    0\n",
       "55    0\n",
       "56    0\n",
       "57    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of above cell is all zero, which indicates that the dataset has no missing values and do not need data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I am spliting the dataset into train dataset and test dataset. I've set the train test ratio to be 80/20, which is a very commonly used ratio number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(dataset.drop(dataset.columns[-1],1), dataset[57], train_size = 0.8, test_size = 0.2, random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the index is random after splitting, I need to reset all the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reset_index(drop = True)\n",
    "train_Y = train_Y.reset_index(drop = True)\n",
    "test_X = test_X.reset_index(drop = True)\n",
    "test_Y = test_Y.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After resetting index, the training and testing set are ready to use for SVM and Naive-Bayes models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a dictionary data structure to store all testing result\n",
    "result = {\n",
    "    'Model': [],\n",
    "    'Accuracy': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing SVM model using three different kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# svm model using linear model\n",
    "svm_linear = svm.SVC(kernel = \"linear\", gamma = 'auto')\n",
    "svm_linear.fit(train_X, train_Y)\n",
    "svm_linear_acc = svm_linear.score(test_X, test_Y)\n",
    "result['Model'].append(\"linear\")\n",
    "result[\"Accuracy\"].append(svm_linear_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model using polynomial kernel\n",
    "svm_poly = svm.SVC(kernel = \"poly\")\n",
    "svm_poly.fit(train_X, train_Y)\n",
    "svm_poly_acc = svm_poly.score(test_X, test_Y)\n",
    "\n",
    "result['Model'].append(\"poly\")\n",
    "result[\"Accuracy\"].append(svm_poly_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm model using sigmodi model\n",
    "svm_sigmoid = svm.SVC(kernel = \"sigmoid\")\n",
    "svm_sigmoid.fit(train_X, train_Y)\n",
    "svm_sigmoid = svm_sigmoid.score(test_X, test_Y)\n",
    "\n",
    "result['Model'].append(\"sigmoid\")\n",
    "result[\"Accuracy\"].append(svm_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and testing two different Naive-Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7709011943539631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Multinomial Naive-Bayes model\n",
    "multi_nb = MultinomialNB().fit(train_X, train_Y)\n",
    "multi_nb_acc = classifier.score(test_X, test_Y)\n",
    "\n",
    "result['Model'].append(\"multinomial\")\n",
    "result[\"Accuracy\"].append(multi_nb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Gaussian Naive-Bayes model\n",
    "gaussian_nb = GaussianNB().fit(train_X, train_Y)\n",
    "gaussian_nb_acc = classifier.score(test_X, test_Y)\n",
    "\n",
    "result['Model'].append(\"gaussian\")\n",
    "result[\"Accuracy\"].append(gaussian_nb_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, I need to further preprocess dataset (including normalization and categorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization: I need to rescale these three attributes \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\" to be ranged from [1, ...] to [0, 100] (same formate as other attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "for i in [54, 55, 56]:\n",
    "    train_X[i] = 100 * NormalizeData(train_X[i])\n",
    "    test_X[i] = 100 * NormalizeData(test_X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorization: Since I will be using \"categorical_crossentropy\" loss function in later neural network, I need train_Y and test_Y to be binary matrix representation of the {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# reformatting outputs to categorical values\n",
    "train_Y = to_categorical(train_Y)\n",
    "test_Y = to_categorical(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data is now what I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1     2    3     4     5     6     7     8     9     ...      47  \\\n",
      "0  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00    ...     0.0   \n",
      "1  0.18  0.00  0.18  0.0  1.59  0.36  0.00  0.06  0.06  0.06    ...     0.0   \n",
      "2  0.17  0.00  0.17  0.0  1.45  0.34  0.05  0.05  0.05  0.05    ...     0.0   \n",
      "3  0.00  0.18  0.00  0.0  0.18  0.00  0.00  0.37  0.00  0.00    ...     0.0   \n",
      "4  0.64  0.00  0.64  0.0  1.29  0.00  0.64  0.00  0.00  0.00    ...     0.0   \n",
      "\n",
      "     48     49   50     51     52   53        54        55        56  \n",
      "0  0.00  0.000  0.0  0.000  0.000  0.0  0.022696  0.010012  0.056818  \n",
      "1  0.01  0.052  0.0  0.010  0.169  0.0  0.067907  0.110132  2.796717  \n",
      "2  0.01  0.051  0.0  0.020  0.163  0.0  0.072265  0.110132  2.897727  \n",
      "3  0.00  0.244  0.0  0.000  0.000  0.0  0.060191  0.090108  1.054293  \n",
      "4  0.00  0.104  0.0  0.522  0.313  0.0  0.137177  0.210252  0.707071  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "                0            1            2            3            4   \\\n",
      "count  3680.000000  3680.000000  3680.000000  3680.000000  3680.000000   \n",
      "mean      0.100557     0.220856     0.281940     0.078959     0.308234   \n",
      "std       0.295054     1.328651     0.503077     1.554935     0.667112   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.430000     0.000000     0.370000   \n",
      "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
      "\n",
      "                5            6            7            8            9   \\\n",
      "count  3680.000000  3680.000000  3680.000000  3680.000000  3680.000000   \n",
      "mean      0.095962     0.115802     0.105799     0.090495     0.244258   \n",
      "std       0.277757     0.388546     0.407232     0.282401     0.665957   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.170000   \n",
      "max       5.880000     7.270000    11.110000     5.260000    18.180000   \n",
      "\n",
      "          ...                47           48           49           50  \\\n",
      "count     ...       3680.000000  3680.000000  3680.000000  3680.000000   \n",
      "mean      ...          0.030859     0.037974     0.139674     0.017180   \n",
      "std       ...          0.262910     0.232633     0.272871     0.117157   \n",
      "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
      "50%       ...          0.000000     0.000000     0.066000     0.000000   \n",
      "75%       ...          0.000000     0.000000     0.190250     0.000000   \n",
      "max       ...         10.000000     4.385000     9.752000     4.081000   \n",
      "\n",
      "                51           52           53           54           55  \\\n",
      "count  3680.000000  3680.000000  3680.000000  3680.000000  3680.000000   \n",
      "mean      0.254529     0.076704     0.047115     0.397018     0.524937   \n",
      "std       0.598344     0.247323     0.472059     3.117834     2.097286   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.053563     0.050060   \n",
      "50%       0.000000     0.000000     0.000000     0.116659     0.140168   \n",
      "75%       0.312250     0.052000     0.000000     0.249319     0.420505   \n",
      "max       9.575000     6.003000    19.829000   100.000000   100.000000   \n",
      "\n",
      "                56  \n",
      "count  3680.000000  \n",
      "mean      1.798208  \n",
      "std       3.984753  \n",
      "min       0.000000  \n",
      "25%       0.208333  \n",
      "50%       0.587121  \n",
      "75%       1.672980  \n",
      "max     100.000000  \n",
      "\n",
      "[8 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())\n",
    "print(train_X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: 57, dtype: int64\n",
      "count    3680.000000\n",
      "mean        0.395109\n",
      "std         0.488940\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         1.000000\n",
      "max         1.000000\n",
      "Name: 57, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_Y.head())\n",
    "print(train_Y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3     4     5    6    7    8    9     ...      47     48  \\\n",
      "0  0.00  0.0  0.0  0.0  0.00  0.79  0.0  0.0  0.0  0.0    ...     0.0  0.000   \n",
      "1  0.00  0.8  0.0  0.0  0.00  0.00  0.0  0.0  0.0  1.6    ...     0.0  0.000   \n",
      "2  0.00  0.0  0.0  0.0  0.81  0.00  0.0  0.0  0.0  0.0    ...     0.0  0.000   \n",
      "3  0.00  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0    ...     0.0  0.000   \n",
      "4  0.74  0.0  0.0  0.0  0.00  0.00  0.0  0.0  0.0  0.0    ...     0.0  0.134   \n",
      "\n",
      "      49   50     51   52   53        54        55        56  \n",
      "0  0.147  0.0  0.000  0.0  0.0  0.568922  1.728723  1.759531  \n",
      "1  0.000  0.0  0.235  0.0  0.0  0.113011  0.199468  0.746468  \n",
      "2  0.143  0.0  0.143  0.0  0.0  0.016357  0.066489  0.479872  \n",
      "3  0.000  0.0  3.048  0.0  0.0  0.000000  0.000000  0.186617  \n",
      "4  0.672  0.0  0.000  0.0  0.0  0.256654  0.265957  1.066382  \n",
      "\n",
      "[5 rows x 57 columns]\n",
      "               0           1           2           3           4           5   \\\n",
      "count  921.000000  921.000000  921.000000  921.000000  921.000000  921.000000   \n",
      "mean     0.120521    0.181683    0.275527    0.011346    0.328165    0.095657   \n",
      "std      0.343169    1.125771    0.508622    0.244772    0.693816    0.257655   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.050000    0.000000    0.380000    0.000000    0.430000    0.000000   \n",
      "max      4.340000   14.280000    4.340000    7.180000    8.330000    3.440000   \n",
      "\n",
      "               6           7           8           9      ...              47  \\\n",
      "count  921.000000  921.000000  921.000000  921.000000     ...      921.000000   \n",
      "mean     0.107839    0.103279    0.088360    0.220054     ...        0.035907   \n",
      "std      0.402956    0.375653    0.263089    0.551873     ...        0.363028   \n",
      "min      0.000000    0.000000    0.000000    0.000000     ...        0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000     ...        0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000     ...        0.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.130000     ...        0.000000   \n",
      "max      7.270000    6.060000    2.290000    5.260000     ...        8.330000   \n",
      "\n",
      "               48          49          50          51          52          53  \\\n",
      "count  921.000000  921.000000  921.000000  921.000000  921.000000  921.000000   \n",
      "mean     0.040974    0.136458    0.016159    0.327176    0.072240    0.032743   \n",
      "std      0.282791    0.260190    0.070331    1.375029    0.240135    0.174328   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.058000    0.000000    0.016000    0.000000    0.000000   \n",
      "75%      0.000000    0.175000    0.000000    0.329000    0.053000    0.000000   \n",
      "max      4.367000    4.271000    1.176000   32.478000    5.300000    3.423000   \n",
      "\n",
      "               54          55          56  \n",
      "count  921.000000  921.000000  921.000000  \n",
      "mean     1.030707    3.068257    7.254410  \n",
      "std      5.292190    7.980613   13.196208  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.174275    0.332447    0.959744  \n",
      "50%      0.364907    0.864362    2.559318  \n",
      "75%      0.758959    2.925532    6.958144  \n",
      "max    100.000000  100.000000  100.000000  \n",
      "\n",
      "[8 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_X.head())\n",
    "print(test_X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: 57, dtype: int64\n",
      "count    921.000000\n",
      "mean       0.389794\n",
      "std        0.487968\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: 57, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_Y.head())\n",
    "print(test_Y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing layers. This neural network includes 1 input layer(57 Neurons), 2 hidden layers(each with 16 neurons) and 1 output layer(2 neurons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer structure: [57, 16, 16, 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "structure = [57, 16, 16, 2]\n",
    "\n",
    "# Input layer + hidden layer 1\n",
    "model.add(keras.layers.Dense(units=structure[1], input_dim = structure[0], activation = 'relu'))\n",
    "\n",
    "# Hidden layer 2\n",
    "model.add(keras.layers.Dense(units=structure[2], activation = 'relu'))\n",
    "\n",
    "# Output layer - note that the activation function is softmax\n",
    "model.add(keras.layers.Dense(units=structure[3], activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1/5\n",
      "3680/3680 [==============================] - 1s 243us/step - loss: 0.6962 - accuracy: 0.6038\n",
      "Epoch 2/5\n",
      "3680/3680 [==============================] - 1s 221us/step - loss: 0.6545 - accuracy: 0.6049\n",
      "Epoch 3/5\n",
      "3680/3680 [==============================] - 1s 214us/step - loss: 0.6524 - accuracy: 0.6049\n",
      "Epoch 4/5\n",
      "3680/3680 [==============================] - 1s 212us/step - loss: 0.6518 - accuracy: 0.6049\n",
      "Epoch 5/5\n",
      "3680/3680 [==============================] - 1s 222us/step - loss: 0.6501 - accuracy: 0.6049\n",
      "Training finished\n",
      "Training Evaluation: loss = 0.650, accuracy = 60.49%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])\n",
    "\n",
    "# Time to fit the model\n",
    "print('Starting training')\n",
    "\n",
    "training_stats = model.fit(train_X, train_Y, batch_size = 4, epochs = 5)\n",
    "\n",
    "print('Training finished')\n",
    "print('Training Evaluation: loss = %0.3f, accuracy = %0.2f%%'\n",
    "      %(training_stats.history['loss'][-1], 100 * training_stats.history['accuracy'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as graph\n",
    "accuracy, = graph.plot(training_stats.history['accuracy'],label = 'Accuracy')\n",
    "training_loss, = graph.plot(training_stats.history['loss'],label = 'Training Loss')\n",
    "\n",
    "\n",
    "graph.legend(handles = [accuracy,training_loss])\n",
    "loss = np.array(training_stats.history['loss'])\n",
    "xp = np.linspace(0, loss.shape[0], 10 * loss.shape[0])\n",
    "graph.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\n",
    "graph.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\n",
    "graph.show()\n",
    "graph.savefig(\"image/neural_network_loss&acc.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation: loss = 0.649378, accuracy = 61.02%\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(test_X, test_Y, verbose=0)\n",
    "###\n",
    "\n",
    "print('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f%%' %(evaluation[0], 100*evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Model'].append(\"Neural Network\")\n",
    "result[\"Accuracy\"].append(evaluation[1])\n",
    "\n",
    "# convert result from dictionary format to DataFrame formate for later plotting\n",
    "data = pd.DataFrame.from_dict(result)\n",
    "data.plot.bar(x = 'Model', y = 'Accuracy', rot = 10)\n",
    "\n",
    "grapg.show()\n",
    "graph.savefig(\"image/accuracy.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
